{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=mnist[\"data\"],mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit=x[37000]\n",
    "some_digit_image=some_digit.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(some_digit_image,cmap=matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[37000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x[:60000]\n",
    "x_test=x[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y[:60000]\n",
    "y_test=y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shuffle_index=np.random.permutation(60000)\n",
    "x_train, y_train=x_train[shuffle_index],y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a 2 detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype(np.int8)\n",
    "y_test=y_test.astype(np.int8)\n",
    "y_train_4=(y_train==2)\n",
    "y_test_4=(y_test==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 6, 3, ..., 0, 7, 3], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       980\n",
      "           1       0.97      0.98      0.97      1135\n",
      "           2       0.93      0.90      0.91      1032\n",
      "           3       0.90      0.91      0.91      1010\n",
      "           4       0.93      0.93      0.93       982\n",
      "           5       0.90      0.87      0.89       892\n",
      "           6       0.94      0.95      0.95       958\n",
      "           7       0.93      0.93      0.93      1028\n",
      "           8       0.87      0.89      0.88       974\n",
      "           9       0.91      0.91      0.91      1009\n",
      "\n",
      "    accuracy                           0.93     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n",
      "[[ 963    0    0    3    1    3    4    4    2    0]\n",
      " [   0 1112    4    2    0    1    3    2   11    0]\n",
      " [   3   10  926   15    6    4   15    8   42    3]\n",
      " [   4    1   21  916    1   26    3    9   22    7]\n",
      " [   1    1    7    3  910    0    9    7   10   34]\n",
      " [  11    2    1   33   11  776   11    6   35    6]\n",
      " [   9    3    7    3    7   16  910    2    1    0]\n",
      " [   1    6   24    5    7    1    0  951    3   30]\n",
      " [   8    7    6   23    6   26   10   10  869    9]\n",
      " [   9    7    0   11   25    6    0   22    7  922]]\n",
      "Training Score: 93.39166666666667\n",
      "The accuracy of the Logistic Regression Model is:  92.55 %\n"
     ]
    }
   ],
   "source": [
    "y_pred=lr_model.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix, mean_squared_error\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Training Score:\", lr_model.score(x_train, y_train)*100)\n",
    "#Printing the accuracy of the model\n",
    "print(\"The accuracy of the Logistic Regression Model is: \", accuracy_score(y_test, y_pred)*100 , \"%\")\n",
    "lr_model_results=accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.97      0.98      1032\n",
      "           3       0.97      0.99      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "           5       0.99      0.98      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.97      0.97      1028\n",
      "           8       0.97      0.98      0.97       974\n",
      "           9       0.97      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n",
      "[[ 973    0    1    0    0    2    1    1    2    0]\n",
      " [   0 1126    3    1    0    1    1    1    2    0]\n",
      " [   6    1 1006    2    1    0    2    7    6    1]\n",
      " [   0    0    2  995    0    2    0    5    5    1]\n",
      " [   0    0    5    0  961    0    3    0    2   11]\n",
      " [   2    0    0    9    0  871    4    1    4    1]\n",
      " [   6    2    0    0    2    3  944    0    1    0]\n",
      " [   0    6   11    1    1    0    0  996    2   11]\n",
      " [   3    0    2    6    3    2    2    3  950    3]\n",
      " [   3    4    1    7   10    2    1    7    4  970]]\n",
      "Training Score:  98.99166666666666\n",
      "The accuracy of the Support Vector Machine Classification Model is:  97.92 %\n"
     ]
    }
   ],
   "source": [
    "y_pred=svc.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,mean_squared_error\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(\"Training Score: \",svc.score(x_train,y_train)*100)\n",
    "#Printing the accuracy of the model\n",
    "print(\"The accuracy of the Support Vector Machine Classification Model is: \", accuracy_score(y_test, y_pred)*100, \"%\")\n",
    "svc_results=accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.52158158\n",
      "Iteration 2, loss = 1.31869875\n",
      "Iteration 3, loss = 1.32786391\n",
      "Iteration 4, loss = 1.25121150\n",
      "Iteration 5, loss = 1.33574530\n",
      "Iteration 6, loss = 1.49049960\n",
      "Iteration 7, loss = 1.33713600\n",
      "Iteration 8, loss = 1.19794590\n",
      "Iteration 9, loss = 1.16263204\n",
      "Iteration 10, loss = 1.10611642\n",
      "Iteration 11, loss = 1.02391193\n",
      "Iteration 12, loss = 1.00727301\n",
      "Iteration 13, loss = 1.03584376\n",
      "Iteration 14, loss = 1.02066612\n",
      "Iteration 15, loss = 1.05130040\n",
      "Iteration 16, loss = 1.21645109\n",
      "Iteration 17, loss = 1.13416127\n",
      "Iteration 18, loss = 0.99217034\n",
      "Iteration 19, loss = 0.97278214\n",
      "Iteration 20, loss = 1.07570097\n",
      "Iteration 21, loss = 0.98174119\n",
      "Iteration 22, loss = 0.92402198\n",
      "Iteration 23, loss = 0.90467186\n",
      "Iteration 24, loss = 1.00457513\n",
      "Iteration 25, loss = 0.95177531\n",
      "Iteration 26, loss = 0.89660170\n",
      "Iteration 27, loss = 0.94901625\n",
      "Iteration 28, loss = 0.97281436\n",
      "Iteration 29, loss = 0.93076740\n",
      "Iteration 30, loss = 0.92487954\n",
      "Iteration 31, loss = 0.93006255\n",
      "Iteration 32, loss = 1.00369635\n",
      "Iteration 33, loss = 0.94214051\n",
      "Iteration 34, loss = 0.85809445\n",
      "Iteration 35, loss = 0.82719169\n",
      "Iteration 36, loss = 0.83566711\n",
      "Iteration 37, loss = 0.85382738\n",
      "Iteration 38, loss = 0.86580595\n",
      "Iteration 39, loss = 0.91658500\n",
      "Iteration 40, loss = 0.89650958\n",
      "Iteration 41, loss = 0.89350985\n",
      "Iteration 42, loss = 0.87382721\n",
      "Iteration 43, loss = 0.91619135\n",
      "Iteration 44, loss = 0.86266921\n",
      "Iteration 45, loss = 0.87464894\n",
      "Iteration 46, loss = 0.83846385\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(15,),\n",
       "              learning_rate_init=0.1, random_state=1, solver='sgd',\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(15,), activation='logistic', alpha=1e-4,\n",
    "                    solver='sgd', tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1, verbose=True)\n",
    "mlp.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90       980\n",
      "           1       0.90      0.92      0.91      1135\n",
      "           2       0.86      0.78      0.82      1032\n",
      "           3       0.80      0.75      0.77      1010\n",
      "           4       0.50      0.88      0.63       982\n",
      "           5       0.76      0.55      0.64       892\n",
      "           6       0.70      0.91      0.79       958\n",
      "           7       0.78      0.86      0.82      1028\n",
      "           8       0.64      0.59      0.61       974\n",
      "           9       0.51      0.10      0.17      1009\n",
      "\n",
      "    accuracy                           0.73     10000\n",
      "   macro avg       0.73      0.73      0.71     10000\n",
      "weighted avg       0.73      0.73      0.71     10000\n",
      "\n",
      "[[ 929    0    2    2    1    9   33    2    2    0]\n",
      " [   1 1045    3    4    0    0    4    1   76    1]\n",
      " [  49    3  809   34   28    3   78   13   15    0]\n",
      " [  28   22   40  753   10   94    6   32   19    6]\n",
      " [   0    6    4    0  868    0   25    7   20   52]\n",
      " [  28    5    5   82   16  493   65   36  140   22]\n",
      " [  13    8    6    1   32    5  873    1   19    0]\n",
      " [   5   14   38   10   29    0    0  889   31   12]\n",
      " [  10   59   27   36   50   42  154   20  573    3]\n",
      " [  11    4    9   15  718    6    9  132    5  100]]\n",
      "Training Score: 72.95166666666667\n",
      "The accuracy of the MLP is:  73.32 %\n"
     ]
    }
   ],
   "source": [
    "y_pred=mlp.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix, mean_squared_error\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "#Confusion_Matrices.append(confusion_matrix(y_test, mlp.predict(x_test)))\n",
    "print(\"Training Score:\", mlp.score(x_train, y_train)*100)\n",
    "#Printing the accuracy of the model\n",
    "print(\"The accuracy of the MLP is: \", accuracy_score(y_test, y_pred)*100 , \"%\")\n",
    "mlp_results=accuracy_score(y_test, y_pred)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
